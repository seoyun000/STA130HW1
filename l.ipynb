{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. \n",
    "1. Count: \n",
    "  Definition : The number of non-missing (non-NaN) entries for each column. This shows how many valid data points there are in each variable.\n",
    "\n",
    "2. Mean:\n",
    " Definition: The arithmetic average of the values in the column. It is calculated as the sum of all values divided by the number of non-missing values.\n",
    "\n",
    "3. Std (Standard Deviation):\n",
    " Definition: A measure of the spread or dispersion of the values from the mean. It indicates how much the values in the column deviate from the mean on average.\n",
    "\n",
    "4. Min (Minimum):\n",
    " Definition: The smallest value in the column.\n",
    "\n",
    "5. 25% (First Quartile or Q1):\n",
    " Definition: The value below which 25% of the data falls. It marks the first quartile of the data distribution.\n",
    "\n",
    "6. 50% (Median or Second Quartile, Q2):\n",
    " Definition: The median value, or the value below which 50% of the data falls. It is also called the second quartile (Q2). This divides the dataset into two equal halves.\n",
    "\n",
    "7.75% (Third Quartile or Q3):\n",
    " Definition: The value below which 75% of the data falls. It marks the third quartile of the data distribution.\n",
    "\n",
    "8.Max (Maximum):\n",
    " Definition: The largest value in the column.\n",
    "\n",
    "Here is some great example that I found!\n",
    "\n",
    "Code from : https://stackoverflow.com/questions/57869926/what-are-25-50-75-values-when-we-describe-a-grouped-dataframe\n",
    "\n",
    "        7.\n",
    "Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "\n",
    "Using del df['col']:\n",
    "del df['col'] is used when you want to remove an entire column, regardless of whether it contains missing values or not. For instance, if you wanted to remove the entire 'City' column, you'd use del df['City'].\n",
    "In summary:\n",
    "Use df.dropna() when you want to remove rows (or columns) with missing values.\n",
    "Use del df['col'] when you want to delete a specific column entirely.\n",
    "Scenario - Suppose you have a DataFrame where some rows contain missing values, and you want to clean up the data by removing those rows, but keeping the rest of the columns intact.\n",
    "\n",
    "\n",
    "Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "\n",
    "\n",
    "Scenario:\n",
    "Suppose you have a DataFrame where you want to completely drop an irrelevant or unneeded column, even if that column doesn't have any missing values. Using del df['col'] allows you to remove that column directly, which would be more efficient than filtering out rows or columns based on NaN values.\n",
    "\n",
    "Using df.dropna():\n",
    "df.dropna() would be more useful if you were trying to remove rows (or columns) based on whether they contain NaN values. However, in this case, where you want to remove the entire column without regard for missing values, del df['col'] is the more appropriate and efficient option.\n",
    "In summary:\n",
    "Use del df['col'] when you need to delete an entire column, regardless of whether it has missing values or not.\n",
    "Use df.dropna() when you need to remove rows (or columns) based on the presence of missing values.\n",
    "\n",
    "Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "Importance of Applying del df['col'] Before df.dropna():\n",
    "Memory Efficiency: Deleting unnecessary columns first reduces the size of the DataFrame, leading to lower memory usage. This can improve the performance of the subsequent dropna() operation.\n",
    "Clarity in Handling Missing Data: If a particular column has many missing values and is not needed for analysis, removing that column before handling missing data allows for more meaningful analysis with the remaining data. Keeping unnecessary columns can create confusion when processing rows with missing values.\n",
    "Error Prevention: If you retain columns with missing values and use dropna(), unexpected errors may arise in subsequent operations. For example, using a column with missing values in calculations can lead to errors. Thus, removing unnecessary columns first can help prevent such issues.\n",
    "Step-by-Step Data Cleaning Approach: Data cleaning should be done in stages for effectiveness. Removing unnecessary columns first and then addressing missing values enhances the quality of the data. This allows for clearer visibility of the data’s state at each step, increasing the reliability of the analysis.\n",
    "For these reasons, applying del df['col'] before df.dropna() can be more effective in data processing.\n",
    "\n",
    "Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.\n",
    "\n",
    "Approach to Remove Missing Data:\n",
    "Remove Unnecessary Columns: Start by deleting columns that contain a high percentage of missing values and are not essential for your analysis. This simplifies the dataset and improves performance.\n",
    "Remove Rows with Missing Values: Next, use dropna() to remove rows that have missing values in critical columns needed for the analysis. This ensures that your analysis is based on complete data.\n",
    "Justification for the Approach:\n",
    "Efficiency: Reducing the dataset size by removing unnecessary columns speeds up subsequent operations.\n",
    "Focus on Relevant Data: Keeping only rows with complete information in essential columns enhances the reliability of the analysis.\n",
    "Improved Data Quality: The final dataset will contain only valid entries, leading to more accurate and meaningful insights.\n",
    "Before and After Report:\n",
    "Before Cleaning: Total number of rows and number of rows with missing values.\n",
    "After Cleaning: Total number of rows and confirmation that no missing values remain in critical columns.\n",
    "This method effectively prepares the dataset for analysis by ensuring data quality and relevance.\n",
    "\n",
    "8.\n",
    "Understanding df.groupby(\"col1\")[\"col2\"].describe()\n",
    "This method groups the DataFrame by a specified column (col1) and then provides descriptive statistics (like count, mean, min, max, etc.) for another column (col2) within each group.\n",
    "\n",
    "Example Explanation:\n",
    "For instance, if we group by the class column in the Titanic dataset and describe the age column, we would get statistics for the ages of passengers in each class (1st, 2nd, 3rd).\n",
    "Differences in Counts from df.describe() vs. df.groupby()\n",
    "df.describe(): This method provides summary statistics for all columns, accounting for missing values. The count reflects how many non-null entries exist across all rows.\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): Here, the count reflects the number of non-null entries within each group defined by col1. This means the counts can differ significantly if some groups have more missing values than others, providing insights into data distribution across categories.\n",
    "Troubleshooting Errors\n",
    "NameError: name 'pd' is not defined: This error occurs when the pandas library is not imported. You can troubleshoot this by simply including import pandas as pd.\n",
    "FileNotFoundError with Mistyped Filename: If you type titanics.csv instead of titanic.csv, the error will indicate that the file cannot be found. Fixing this is straightforward: ensure the filename is correct.\n",
    "Typos in URLs: Introducing typos in parts of the URL will generate different errors, often indicating invalid URL formats or connection issues.\n",
    "Using a Variable Before Assignment: If you try to use a DataFrame variable that hasn’t been defined yet (e.g., DF instead of df), you will get a NameError.\n",
    "Missing Parentheses: Omitting a parenthesis in function calls can lead to syntax errors, which can be easily identified and fixed.\n",
    "Mistyped Function Names: If you use group_by instead of groupby, Python will return an AttributeError, indicating that the DataFrame object doesn't have that attribute.\n",
    "Invalid Column Names: Using a capitalized column name that doesn't exist (like \"Sex\" instead of \"sex\") will generate a KeyError.\n",
    "Missing Quotes for Column Names: Omitting quotes around column names will lead to a NameError, as Python will interpret them as variable names.\n",
    "Forgetting Import Statement: Not including import pandas as pd will result in a NameError whenever you try to use pd.\n",
    "Evaluating Troubleshooting Methods\n",
    "ChatBot vs. Google:\n",
    "Using a ChatBot can provide conversational guidance and clarification on errors, making it easier to understand the underlying issues.\n",
    "Google searches can yield quick results and often provide examples or documentation that may help in resolving errors faster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "9. \n",
    "Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?\n",
    "\n",
    "Yes.\n",
    "\n",
    "Link \n",
    "https://chatgpt.com/share/66e3890a-03a4-800b-be62-0a8a9a999d8b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
